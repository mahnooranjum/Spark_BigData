{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61bbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec807e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7feec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 01:10:53 WARN Utils: Your hostname, maq-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "21/11/24 01:10:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/maq/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/24 01:10:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Basic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5472c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/home/maq/Datasets/customer_churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66463fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db5d4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Total_Purchase: string (nullable = true)\n",
      " |-- Account_Manager: string (nullable = true)\n",
      " |-- Years: string (nullable = true)\n",
      " |-- Num_Sites: string (nullable = true)\n",
      " |-- Onboard_date: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/home/maq/Datasets/customer_churn.csv\", header = True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f068d3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a00544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Names: string, Age: string, Total_Purchase: string, Account_Manager: string, Years: string, Num_Sites: string, Onboard_date: string, Location: string, Company: string, Churn: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8276dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Total_Purchase: string (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/home/maq/Datasets/customer_churn.csv\", header = True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e207e0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Onboard_date='2013-08-30 07:00:40')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Onboard_date').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adacde27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (dayofmonth, \n",
    "                                   hour, \n",
    "                                   month, \n",
    "                                   weekofyear,\n",
    "                                   dayofyear, \n",
    "                                   format_number, \n",
    "                                   year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ba2417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|dayofmonth(Onboard_date)|\n",
      "+------------------------+\n",
      "|                      30|\n",
      "|                    null|\n",
      "|                      13|\n",
      "|                    null|\n",
      "|                      29|\n",
      "|                    null|\n",
      "|                      22|\n",
      "|                    null|\n",
      "|                      19|\n",
      "|                    null|\n",
      "|                       3|\n",
      "|                    null|\n",
      "|                       5|\n",
      "|                    null|\n",
      "|                       9|\n",
      "|                    null|\n",
      "|                      29|\n",
      "|                    null|\n",
      "|                      28|\n",
      "|                    null|\n",
      "+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofmonth(df['Onboard_date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df16a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|month(Onboard_date)|\n",
      "+-------------------+\n",
      "|                  8|\n",
      "|               null|\n",
      "|                  8|\n",
      "|               null|\n",
      "|                  6|\n",
      "|               null|\n",
      "|                  4|\n",
      "|               null|\n",
      "|                  1|\n",
      "|               null|\n",
      "|                  3|\n",
      "|               null|\n",
      "|                 12|\n",
      "|               null|\n",
      "|                  3|\n",
      "|               null|\n",
      "|                  9|\n",
      "|               null|\n",
      "|                  3|\n",
      "|               null|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(month(df['Onboard_date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73b1e4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|hour(Onboard_date)|\n",
      "+------------------+\n",
      "|                 7|\n",
      "|              null|\n",
      "|                 0|\n",
      "|              null|\n",
      "|                 6|\n",
      "|              null|\n",
      "|                12|\n",
      "|              null|\n",
      "|                15|\n",
      "|              null|\n",
      "|                23|\n",
      "|              null|\n",
      "|                 3|\n",
      "|              null|\n",
      "|                14|\n",
      "|              null|\n",
      "|                 5|\n",
      "|              null|\n",
      "|                15|\n",
      "|              null|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(hour(df['Onboard_date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc5dd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('Year', year(df['Onboard_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "078d5753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Total_Purchase: string (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e7f67d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Year|count|\n",
      "+----+-----+\n",
      "|2007|   90|\n",
      "|2015|   75|\n",
      "|2006|  102|\n",
      "|2013|   80|\n",
      "|2014|  103|\n",
      "|2012|   67|\n",
      "|2009|   84|\n",
      "|2016|   67|\n",
      "|2010|   84|\n",
      "|2011|   72|\n",
      "|2008|   76|\n",
      "|null|  900|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Year').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f67d2791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+-----------------+---------+\n",
      "|Year|avg(Account_Manager)|        avg(Years)|   avg(Num_Sites)|avg(Year)|\n",
      "+----+--------------------+------------------+-----------------+---------+\n",
      "|2007|                 0.5| 5.338000000000002|8.655555555555555|   2007.0|\n",
      "|2015|  0.5066666666666667| 5.117200000000001|8.733333333333333|   2015.0|\n",
      "|2006| 0.43137254901960786|5.3656862745098035|8.627450980392156|   2006.0|\n",
      "|2013|              0.4375|          5.127375|            8.325|   2013.0|\n",
      "|2014|  0.5048543689320388| 5.204368932038836| 8.41747572815534|   2014.0|\n",
      "|2012|  0.4626865671641791| 5.197462686567163|8.716417910447761|   2012.0|\n",
      "|2009| 0.47619047619047616| 5.245000000000002|8.416666666666666|   2009.0|\n",
      "|2016|  0.4925373134328358| 5.208955223880596|8.492537313432836|   2016.0|\n",
      "|2010|  0.4642857142857143| 5.130952380952381|8.738095238095237|   2010.0|\n",
      "|2011|  0.5277777777777778| 5.815000000000001|8.527777777777779|   2011.0|\n",
      "|2008|                 0.5| 5.271052631578949|8.868421052631579|   2008.0|\n",
      "|null|  0.1664564943253468|              null|             null|     null|\n",
      "+----+--------------------+------------------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Year').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669b1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
